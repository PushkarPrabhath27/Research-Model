{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DPO Training - 411 Clean Gricean Pairs\n",
                "\n",
                "**Important Instructions:**\n",
                "1. Enable GPU: Settings ‚Üí Accelerator ‚Üí GPU T4 x2\n",
                "2. Add your dataset: + Add Data ‚Üí gricebench-clean-dpo\n",
                "3. Run Cell 1, then RESTART KERNEL\n",
                "4. Run Cell 2 (this does everything and saves automatically)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# CELL 1: INSTALL PACKAGES\n",
                "# After this cell, RESTART THE KERNEL!\n",
                "# Runtime ‚Üí Restart session\n",
                "# ============================================\n",
                "\n",
                "# Install without breaking Kaggle's environment\n",
                "!pip install -q trl==0.8.6 peft==0.10.0 bitsandbytes accelerate --no-deps\n",
                "!pip install -q safetensors huggingface_hub\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"‚úÖ INSTALLATION COMPLETE!\")\n",
                "print(\"=\"*50)\n",
                "print(\"\\n‚ö†Ô∏è  NOW RESTART THE KERNEL:\")\n",
                "print(\"    Runtime ‚Üí Restart session\")\n",
                "print(\"\\nThen run Cell 2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# CELL 2: COMPLETE TRAINING PIPELINE\n",
                "# This cell does EVERYTHING:\n",
                "# - Loads data\n",
                "# - Loads model\n",
                "# - Trains DPO\n",
                "# - Saves model\n",
                "# - Zips for download\n",
                "# ============================================\n",
                "\n",
                "import os\n",
                "import json\n",
                "import torch\n",
                "import shutil\n",
                "from datasets import Dataset\n",
                "from transformers import (\n",
                "    AutoModelForCausalLM,\n",
                "    AutoTokenizer,\n",
                "    BitsAndBytesConfig,\n",
                "    TrainingArguments\n",
                ")\n",
                "from peft import LoraConfig, prepare_model_for_kbit_training\n",
                "from trl import DPOTrainer\n",
                "\n",
                "print(\"‚úÖ All imports successful!\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 1: LOAD DATA\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 1: Loading data...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Try multiple possible paths\n",
                "possible_paths = [\n",
                "    \"/kaggle/input/gricebench-clean-dpo/clean_dpo_pairs.json\",\n",
                "    \"/kaggle/input/clean-dpo-pairs/clean_dpo_pairs.json\",\n",
                "    \"/kaggle/input/gricebench/clean_dpo_pairs.json\"\n",
                "]\n",
                "\n",
                "DATA_PATH = None\n",
                "for path in possible_paths:\n",
                "    if os.path.exists(path):\n",
                "        DATA_PATH = path\n",
                "        break\n",
                "\n",
                "if DATA_PATH is None:\n",
                "    print(\"‚ùå ERROR: Could not find clean_dpo_pairs.json\")\n",
                "    print(\"Available datasets:\")\n",
                "    for item in os.listdir(\"/kaggle/input\"):\n",
                "        print(f\"  - /kaggle/input/{item}\")\n",
                "    raise FileNotFoundError(\"Please check your dataset path!\")\n",
                "\n",
                "print(f\"Found data at: {DATA_PATH}\")\n",
                "\n",
                "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
                "    clean_pairs = json.load(f)\n",
                "\n",
                "print(f\"Loaded {len(clean_pairs)} clean DPO pairs\")\n",
                "\n",
                "# Prepare dataset\n",
                "formatted = []\n",
                "for p in clean_pairs:\n",
                "    formatted.append({\n",
                "        'prompt': p['prompt'],\n",
                "        'chosen': p['chosen'],\n",
                "        'rejected': p['rejected']\n",
                "    })\n",
                "\n",
                "dataset = Dataset.from_list(formatted)\n",
                "split = dataset.train_test_split(test_size=0.1, seed=42)\n",
                "train_dataset = split['train']\n",
                "eval_dataset = split['test']\n",
                "\n",
                "print(f\"Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 2: LOAD MODEL\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 2: Loading model...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "MODEL_NAME = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
                "\n",
                "# 4-bit quantization for memory efficiency\n",
                "bnb_config = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_compute_dtype=torch.float16,\n",
                "    bnb_4bit_use_double_quant=True\n",
                ")\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    quantization_config=bnb_config,\n",
                "    device_map=\"auto\",\n",
                "    trust_remote_code=True\n",
                ")\n",
                "\n",
                "# Prepare for training\n",
                "model = prepare_model_for_kbit_training(model)\n",
                "\n",
                "# Load tokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
                "if tokenizer.pad_token is None:\n",
                "    tokenizer.pad_token = tokenizer.eos_token\n",
                "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
                "\n",
                "print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 3: CONFIGURE LORA\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 3: Configuring LoRA...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "lora_config = LoraConfig(\n",
                "    r=16,\n",
                "    lora_alpha=32,\n",
                "    lora_dropout=0.05,\n",
                "    bias=\"none\",\n",
                "    task_type=\"CAUSAL_LM\",\n",
                "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
                ")\n",
                "\n",
                "print(\"‚úÖ LoRA config ready\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 4: CONFIGURE TRAINING\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 4: Configuring training...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "OUTPUT_DIR = \"/kaggle/working/dpo_411\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=OUTPUT_DIR,\n",
                "    num_train_epochs=5,\n",
                "    per_device_train_batch_size=2,\n",
                "    per_device_eval_batch_size=2,\n",
                "    gradient_accumulation_steps=4,\n",
                "    learning_rate=5e-5,\n",
                "    warmup_ratio=0.1,\n",
                "    logging_steps=10,\n",
                "    eval_strategy=\"steps\",\n",
                "    eval_steps=50,\n",
                "    save_strategy=\"steps\",\n",
                "    save_steps=50,\n",
                "    save_total_limit=2,\n",
                "    fp16=True,\n",
                "    report_to=\"none\",\n",
                "    remove_unused_columns=False,\n",
                "    dataloader_pin_memory=False\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Training config ready\")\n",
                "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
                "print(f\"   Batch size: {training_args.per_device_train_batch_size}\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 5: INITIALIZE DPO TRAINER\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 5: Initializing DPO Trainer...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# NOTE: ref_model=None when using peft_config\n",
                "# DPO will use the base model as reference automatically\n",
                "dpo_trainer = DPOTrainer(\n",
                "    model=model,\n",
                "    ref_model=None,  # Required when using peft_config\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=eval_dataset,\n",
                "    tokenizer=tokenizer,\n",
                "    peft_config=lora_config,\n",
                "    beta=0.1,\n",
                "    max_length=512,\n",
                "    max_prompt_length=256\n",
                ")\n",
                "\n",
                "print(\"‚úÖ DPO Trainer initialized!\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 6: TRAIN\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 6: Starting training...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "train_result = dpo_trainer.train()\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"‚úÖ TRAINING COMPLETE!\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# ============================================\n",
                "# STEP 7: SAVE MODEL (IMMEDIATELY!)\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 7: Saving model...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "FINAL_DIR = \"/kaggle/working/dpo_411_final\"\n",
                "os.makedirs(FINAL_DIR, exist_ok=True)\n",
                "\n",
                "# Save model and tokenizer\n",
                "dpo_trainer.save_model(FINAL_DIR)\n",
                "tokenizer.save_pretrained(FINAL_DIR)\n",
                "\n",
                "print(f\"‚úÖ Model saved to {FINAL_DIR}\")\n",
                "\n",
                "# List saved files\n",
                "print(\"\\nSaved files:\")\n",
                "for f in os.listdir(FINAL_DIR):\n",
                "    size = os.path.getsize(os.path.join(FINAL_DIR, f)) / 1024\n",
                "    print(f\"   {f}: {size:.1f} KB\")\n",
                "\n",
                "# ============================================\n",
                "# STEP 8: ZIP FOR DOWNLOAD\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"STEP 8: Creating zip file...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "ZIP_PATH = \"/kaggle/working/dpo_411_model\"\n",
                "shutil.make_archive(ZIP_PATH, 'zip', FINAL_DIR)\n",
                "\n",
                "zip_size = os.path.getsize(ZIP_PATH + \".zip\") / 1024 / 1024\n",
                "print(f\"\\n‚úÖ ZIP CREATED: {ZIP_PATH}.zip ({zip_size:.1f} MB)\")\n",
                "\n",
                "# ============================================\n",
                "# DONE!\n",
                "# ============================================\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"üéâ ALL DONE!\")\n",
                "print(\"=\"*50)\n",
                "print(\"\\nDownload your model:\")\n",
                "print(\"1. Click on the folder icon (üìÅ) on the left\")\n",
                "print(\"2. Navigate to /kaggle/working/\")\n",
                "print(\"3. Download 'dpo_411_model.zip'\")\n",
                "print(\"\\nOr go to Output tab after saving the notebook.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# OPTIONAL: TEST THE MODEL\n",
                "# ============================================\n",
                "\n",
                "def generate(prompt, max_tokens=100):\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    with torch.no_grad():\n",
                "        out = model.generate(**inputs, max_new_tokens=max_tokens, do_sample=True, temperature=0.7)\n",
                "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
                "\n",
                "test_prompt = \"Context: [agent_1]: Do you like Star Wars?\\nEvidence: Personal Knowledge\\n\\nGenerate a cooperative response:\"\n",
                "print(f\"Prompt: {test_prompt}\")\n",
                "print(f\"\\nResponse: {generate(test_prompt)}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}