{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GriceBench Part 3B: Remaining Baselines\n",
                "\n",
                "Runs **3 smaller models** (~40-60 min total):\n",
                "- Llama-3.2-3B-Instruct\n",
                "- Phi-3-mini-4k\n",
                "- Gemma-2-2B-it\n",
                "\n",
                "**Setup:** GPU T4 x2 + Internet ON"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers>=4.40.0 accelerate sentencepiece sentence-transformers\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, json, gc, sys, time\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "import numpy as np\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "def log(m): print(m); sys.stdout.flush()\n",
                "\n",
                "CONFIG = {\"num_samples\": 150, \"max_new_tokens\": 200, \"output_dir\": \"/kaggle/working/baseline_remaining\"}\n",
                "BASELINES = {\n",
                "    \"llama3.2_3b\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
                "    \"phi3_mini\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
                "    \"gemma2_2b\": \"google/gemma-2-2b-it\",\n",
                "}\n",
                "Path(CONFIG[\"output_dir\"]).mkdir(parents=True, exist_ok=True)\n",
                "log(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test prompts\n",
                "TEST_PROMPTS = [\n",
                "    {\"context\": \"What is the capital of France?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"How many planets are in our solar system?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"Who wrote Romeo and Juliet?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What year did World War II end?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What is the chemical symbol for gold?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What is the speed of light?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"Who discovered penicillin?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What is the largest organ in the human body?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"Which planet has the most moons?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What is the smallest country by area?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What is the Pythagorean theorem?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"Who painted the Mona Lisa?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What is the boiling point of water?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"What does DNA stand for?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"Who invented the telephone?\", \"type\": \"factual\"},\n",
                "    {\"context\": \"How does photosynthesis work?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"Why is the sky blue?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How do vaccines work?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"What causes earthquakes?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How does the internet work?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"Why do we dream?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"What is machine learning?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How do airplanes fly?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"Why do leaves change color?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How does electricity work?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"What causes inflation?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How does GPS work?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How do black holes form?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"What is blockchain technology?\", \"type\": \"explanation\"},\n",
                "    {\"context\": \"How can I improve my sleep quality?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"What's a good way to learn a new language?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"How do I make friends in a new city?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"What's the best way to save money?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"How can I be more productive?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"How should I prepare for a job interview?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"What's a healthy diet look like?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"How can I reduce stress?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"What's the best way to learn to code?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"How do I negotiate a salary raise?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"How can I build better habits?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"What's a good exercise routine for beginners?\", \"type\": \"advice\"},\n",
                "    {\"context\": \"What's your favorite food?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"How was your day?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"What do you like to do for fun?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"Do you have any hobbies?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"What kind of music do you enjoy?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"Do you prefer cats or dogs?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"What's your dream vacation destination?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"If you could have any superpower, what would it be?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"What's your favorite book?\", \"type\": \"conversational\"},\n",
                "    {\"context\": \"What is the difference between Python and JavaScript?\", \"type\": \"technical\"},\n",
                "    {\"context\": \"Explain object-oriented programming.\", \"type\": \"technical\"},\n",
                "    {\"context\": \"What is a REST API?\", \"type\": \"technical\"},\n",
                "    {\"context\": \"How do neural networks learn?\", \"type\": \"technical\"},\n",
                "    {\"context\": \"What's the difference between SQL and NoSQL?\", \"type\": \"technical\"},\n",
                "    {\"context\": \"Explain recursion in programming.\", \"type\": \"technical\"},\n",
                "    {\"context\": \"What is Big O notation?\", \"type\": \"technical\"},\n",
                "    {\"context\": \"Write a short poem about the ocean.\", \"type\": \"creative\"},\n",
                "    {\"context\": \"Describe a perfect day.\", \"type\": \"creative\"},\n",
                "    {\"context\": \"Write a haiku about autumn.\", \"type\": \"creative\"},\n",
                "]\n",
                "\n",
                "import random\n",
                "random.seed(42)\n",
                "while len(TEST_PROMPTS) < CONFIG[\"num_samples\"]:\n",
                "    TEST_PROMPTS.append(random.choice(TEST_PROMPTS[:60]).copy())\n",
                "TEST_PROMPTS = TEST_PROMPTS[:CONFIG[\"num_samples\"]]\n",
                "log(f\"Prompts: {len(TEST_PROMPTS)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load evaluator\n",
                "log(\"Loading evaluator...\")\n",
                "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "\n",
                "def evaluate(context, response):\n",
                "    emb = encoder.encode([context, response], normalize_embeddings=True)\n",
                "    relevance = float(np.dot(emb[0], emb[1]))\n",
                "    words = len(response.split())\n",
                "    quantity = 1.0 if 15 <= words <= 150 else 0.5 if words < 15 else 0.7\n",
                "    unique = len(set(response.lower().split())) / max(1, len(response.split()))\n",
                "    clarity = min(1.0, unique * 1.2)\n",
                "    overall = relevance * 0.4 + quantity * 0.3 + clarity * 0.3\n",
                "    return {\"relevance\": relevance, \"quantity\": quantity, \"clarity\": clarity, \"overall\": overall}\n",
                "\n",
                "log(\"Evaluator ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generator functions\n",
                "def cleanup():\n",
                "    gc.collect()\n",
                "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
                "\n",
                "def load_model(model_id):\n",
                "    log(f\"   Loading {model_id}...\")\n",
                "    cleanup()\n",
                "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
                "    if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token\n",
                "    model = AutoModelForCausalLM.from_pretrained(\n",
                "        model_id, trust_remote_code=True, device_map=\"auto\",\n",
                "        torch_dtype=torch.float16, low_cpu_mem_usage=True\n",
                "    )\n",
                "    model.eval()\n",
                "    log(f\"   âœ… GPU: {torch.cuda.memory_allocated()/1e9:.1f} GB\")\n",
                "    return model, tokenizer\n",
                "\n",
                "def generate(model, tokenizer, context, model_name):\n",
                "    # Build prompt\n",
                "    if hasattr(tokenizer, \"chat_template\") and tokenizer.chat_template:\n",
                "        msgs = [{\"role\": \"user\", \"content\": context}]\n",
                "        prompt = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
                "    elif \"phi\" in model_name.lower():\n",
    "        prompt = f\"