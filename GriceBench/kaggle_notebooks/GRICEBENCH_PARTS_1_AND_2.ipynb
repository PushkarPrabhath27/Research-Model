{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GriceBench Improvements: Parts 1 & 2\n",
    "\n",
    "This notebook implements:\n",
    "- **Part 1**: Fixing Relation Repair (Retrieval-Augmented Generation)\n",
    "- **Part 2**: Human Evaluation Framework Setup\n",
    "\n",
    "## How to Use:\n",
    "1. Upload this notebook to Kaggle\n",
    "2. Enable GPU (Settings ‚Üí Accelerator ‚Üí GPU T4 x2)\n",
    "3. Enable Internet (Settings ‚Üí Internet ‚Üí On)\n",
    "4. Run All Cells\n",
    "5. Download outputs from `/kaggle/working/`\n",
    "\n",
    "**Estimated Runtime**: ~15-20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q sentence-transformers faiss-cpu datasets gradio krippendorff\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Create Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directories\n",
    "dirs = [\n",
    "    '/kaggle/working/data_processed',\n",
    "    '/kaggle/working/human_eval_results',\n",
    "    '/kaggle/working/results/relation_repair_evaluation',\n",
    "    '/kaggle/working/reports'\n",
    "]\n",
    "\n",
    "for d in dirs:\n",
    "    Path(d).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created: {d}\")\n",
    "\n",
    "os.chdir('/kaggle/working')\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 1: Fixing Relation Repair Problem\n",
    "\n",
    "The current repair model only achieves 9.3% BLEU on Relation violations because it tries to \"edit\" off-topic text into on-topic text - an impossible task.\n",
    "\n",
    "**Solution**: Use retrieval-augmented generation instead of editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Part 1 Step 1 - Create Response Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Part 1, Step 1: Create Topical Response Corpus\n",
    "Downloads free dialogue datasets and organizes by topic.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "# Topic taxonomy with keywords\n",
    "TOPIC_TAXONOMY = {\n",
    "    \"weather\": [\"weather\", \"rain\", \"sunny\", \"cold\", \"hot\", \"temperature\", \"storm\"],\n",
    "    \"food\": [\"food\", \"eat\", \"restaurant\", \"cook\", \"meal\", \"dinner\", \"lunch\", \"breakfast\"],\n",
    "    \"work\": [\"work\", \"job\", \"office\", \"boss\", \"meeting\", \"project\", \"career\"],\n",
    "    \"family\": [\"family\", \"mother\", \"father\", \"sister\", \"brother\", \"parents\", \"kids\"],\n",
    "    \"travel\": [\"travel\", \"trip\", \"vacation\", \"flight\", \"hotel\", \"visit\", \"beach\"],\n",
    "    \"health\": [\"health\", \"doctor\", \"sick\", \"medicine\", \"hospital\", \"exercise\"],\n",
    "    \"entertainment\": [\"movie\", \"film\", \"music\", \"game\", \"show\", \"concert\", \"book\"],\n",
    "    \"sports\": [\"sport\", \"team\", \"play\", \"win\", \"match\", \"football\", \"basketball\"],\n",
    "    \"education\": [\"school\", \"study\", \"learn\", \"class\", \"teacher\", \"student\"],\n",
    "    \"technology\": [\"computer\", \"phone\", \"internet\", \"app\", \"software\", \"tech\"],\n",
    "    \"pets\": [\"pet\", \"dog\", \"cat\", \"animal\", \"puppy\"],\n",
    "    \"hobbies\": [\"hobby\", \"art\", \"painting\", \"music\", \"garden\"],\n",
    "    \"shopping\": [\"shop\", \"buy\", \"store\", \"price\", \"sale\"],\n",
    "    \"relationship\": [\"friend\", \"relationship\", \"date\", \"love\", \"partner\"],\n",
    "}\n",
    "\n",
    "def extract_topic(text):\n",
    "    \"\"\"Extract topic from text using keyword matching.\"\"\"\n",
    "    if not text:\n",
    "        return \"general\"\n",
    "    text_lower = text.lower()\n",
    "    for topic, keywords in TOPIC_TAXONOMY.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in text_lower:\n",
    "                return topic\n",
    "    return \"general\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def is_quality_response(response, min_len=10, max_len=150):\n",
    "    \"\"\"Check if response meets quality criteria.\"\"\"\n",
    "    words = response.split()\n",
    "    if len(words) < min_len or len(words) > max_len:\n",
    "        return False\n",
    "    if response.count('?') > 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading dialogue datasets from HuggingFace...\")\n",
    "from datasets import load_dataset\n",
    "\n",
    "corpus = defaultdict(list)\n",
    "total_examples = 0\n",
    "\n",
    "# Dataset 1: Daily Dialog\n",
    "print(\"\\nüì• Loading daily_dialog...\")\n",
    "try:\n",
    "    dd = load_dataset(\"daily_dialog\", split=\"train\", trust_remote_code=True)\n",
    "    for item in dd:\n",
    "        dialog = item.get(\"dialog\", [])\n",
    "        for i in range(1, len(dialog)):\n",
    "            context = clean_text(dialog[i-1])\n",
    "            response = clean_text(dialog[i])\n",
    "            if context and response and is_quality_response(response):\n",
    "                topic = extract_topic(f\"{context} {response}\")\n",
    "                corpus[topic].append({\"context\": context, \"response\": response, \"source\": \"daily_dialog\"})\n",
    "                total_examples += 1\n",
    "    print(f\"   ‚úÖ Extracted {total_examples} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Could not load: {e}\")\n",
    "\n",
    "# Dataset 2: Empathetic Dialogues\n",
    "print(\"\\nüì• Loading empathetic_dialogues...\")\n",
    "prev_total = total_examples\n",
    "try:\n",
    "    ed = load_dataset(\"empathetic_dialogues\", split=\"train\", trust_remote_code=True)\n",
    "    convos = defaultdict(list)\n",
    "    for item in ed:\n",
    "        conv_id = item.get(\"conv_id\", \"\")\n",
    "        utterance = clean_text(item.get(\"utterance\", \"\"))\n",
    "        if conv_id and utterance:\n",
    "            convos[conv_id].append(utterance)\n",
    "    for conv_id, utts in convos.items():\n",
    "        for i in range(1, len(utts)):\n",
    "            context, response = utts[i-1], utts[i]\n",
    "            if context and response and is_quality_response(response):\n",
    "                topic = extract_topic(f\"{context} {response}\")\n",
    "                corpus[topic].append({\"context\": context, \"response\": response, \"source\": \"empathetic_dialogues\"})\n",
    "                total_examples += 1\n",
    "    print(f\"   ‚úÖ Extracted {total_examples - prev_total} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Could not load: {e}\")\n",
    "\n",
    "# Dataset 3: Blended Skill Talk\n",
    "print(\"\\nüì• Loading blended_skill_talk...\")\n",
    "prev_total = total_examples\n",
    "try:\n",
    "    bst = load_dataset(\"blended_skill_talk\", split=\"train\", trust_remote_code=True)\n",
    "    for item in bst:\n",
    "        msgs = list(item.get(\"previous_utterance\", [])) + list(item.get(\"free_messages\", []))\n",
    "        for i in range(1, len(msgs)):\n",
    "            context = clean_text(msgs[i-1])\n",
    "            response = clean_text(msgs[i])\n",
    "            if context and response and is_quality_response(response):\n",
    "                topic = extract_topic(f\"{context} {response}\")\n",
    "                corpus[topic].append({\"context\": context, \"response\": response, \"source\": \"blended_skill_talk\"})\n",
    "                total_examples += 1\n",
    "    print(f\"   ‚úÖ Extracted {total_examples - prev_total} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Could not load: {e}\")\n",
    "\n",
    "# Balance corpus (max 5000 per topic)\n",
    "print(\"\\n‚öñÔ∏è Balancing corpus...\")\n",
    "for topic in corpus:\n",
    "    if len(corpus[topic]) > 5000:\n",
    "        corpus[topic] = corpus[topic][:5000]\n",
    "\n",
    "# Save\n",
    "corpus_path = '/kaggle/working/data_processed/topical_corpus.json'\n",
    "with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(dict(corpus), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORPUS CREATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal examples: {sum(len(v) for v in corpus.values()):,}\")\n",
    "print(f\"Topics: {len(corpus)}\")\n",
    "print(f\"\\nSaved to: {corpus_path}\")\n",
    "print(\"\\nPer-topic counts:\")\n",
    "for topic in sorted(corpus.keys(), key=lambda x: len(corpus[x]), reverse=True):\n",
    "    print(f\"  {topic}: {len(corpus[topic]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Part 1 Step 2 - Build FAISS Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Part 1, Step 2: Build FAISS Retrieval System\n",
    "Creates vector index for semantic search.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "print(\"Loading corpus...\")\n",
    "with open('/kaggle/working/data_processed/topical_corpus.json', 'r') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "# Flatten corpus\n",
    "all_responses = []\n",
    "response_metadata = []\n",
    "\n",
    "for topic, responses in corpus.items():\n",
    "    for resp in responses:\n",
    "        all_responses.append(resp[\"response\"])\n",
    "        response_metadata.append({\n",
    "            \"topic\": topic,\n",
    "            \"context\": resp[\"context\"],\n",
    "            \"response\": resp[\"response\"],\n",
    "            \"source\": resp.get(\"source\", \"unknown\")\n",
    "        })\n",
    "\n",
    "print(f\"Total responses to index: {len(all_responses):,}\")\n",
    "\n",
    "# Load encoder\n",
    "print(\"\\nLoading sentence encoder (all-MiniLM-L6-v2)...\")\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Embedding dimension: {encoder.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Encode all responses\n",
    "print(\"\\nEncoding responses (this takes a few minutes)...\")\n",
    "embeddings = encoder.encode(\n",
    "    all_responses,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True  # For cosine similarity\n",
    ")\n",
    "\n",
    "# Create FAISS index\n",
    "print(\"\\nBuilding FAISS index...\")\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner product = cosine after normalization\n",
    "index.add(embeddings.astype(np.float32))\n",
    "print(f\"Index built: {index.ntotal} vectors, {dimension}D\")\n",
    "\n",
    "# Save index and metadata\n",
    "index_path = '/kaggle/working/data_processed/faiss_index.pkl'\n",
    "\n",
    "# Serialize FAISS index\n",
    "writer = faiss.VectorIOWriter()\n",
    "faiss.write_index(index, writer)\n",
    "index_bytes = writer.get_bytes()\n",
    "\n",
    "save_data = {\n",
    "    \"index_bytes\": index_bytes,\n",
    "    \"response_metadata\": response_metadata,\n",
    "    \"all_responses\": all_responses\n",
    "}\n",
    "\n",
    "with open(index_path, 'wb') as f:\n",
    "    pickle.dump(save_data, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Index saved to: {index_path}\")\n",
    "print(f\"   File size: {Path(index_path).stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Part 1 Step 3 - Test Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1, Step 3: Test the Retrieval System\n",
    "Demonstrates that Relation repair now works!\n",
    "\"\"\"\n",
    "\n",
    "class RelationRepairRetriever:\n",
    "    \"\"\"Retrieval-based Relation repair.\"\"\"\n",
    "    \n",
    "    def __init__(self, index_path='/kaggle/working/data_processed/faiss_index.pkl'):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        import faiss\n",
    "        import pickle\n",
    "        \n",
    "        print(\"Loading retrieval system...\")\n",
    "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        with open(index_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        reader = faiss.VectorIOReader()\n",
    "        reader.set_bytes(data[\"index_bytes\"])\n",
    "        self.index = faiss.read_index(reader)\n",
    "        self.metadata = data[\"response_metadata\"]\n",
    "        print(f\"Loaded {self.index.ntotal} vectors\")\n",
    "    \n",
    "    def repair_relation_violation(self, context, violated_response, k=5):\n",
    "        \"\"\"Find relevant response for the context.\"\"\"\n",
    "        # Encode context\n",
    "        query = self.encoder.encode([context], normalize_embeddings=True).astype(np.float32)\n",
    "        \n",
    "        # Search\n",
    "        distances, indices = self.index.search(query, k)\n",
    "        \n",
    "        if indices[0][0] == -1:\n",
    "            return violated_response\n",
    "        \n",
    "        return self.metadata[indices[0][0]][\"response\"]\n",
    "    \n",
    "    def get_relevance_score(self, context, response):\n",
    "        \"\"\"Calculate semantic similarity.\"\"\"\n",
    "        embeddings = self.encoder.encode([context, response], normalize_embeddings=True)\n",
    "        return float(np.dot(embeddings[0], embeddings[1]))\n",
    "\n",
    "# Test!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING RELATION REPAIR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "retriever = RelationRepairRetriever()\n",
    "\n",
    "test_cases = [\n",
    "    (\"What is your favorite food?\", \"The stock market closed up 2% yesterday.\"),\n",
    "    (\"Do you have any pets?\", \"I think the weather will be nice tomorrow.\"),\n",
    "    (\"How was your weekend?\", \"The capital of France is Paris.\"),\n",
    "]\n",
    "\n",
    "for i, (context, violated) in enumerate(test_cases, 1):\n",
    "    print(f\"\\n--- Test Case {i} ---\")\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"Violated (off-topic): {violated}\")\n",
    "    \n",
    "    orig_score = retriever.get_relevance_score(context, violated)\n",
    "    repaired = retriever.repair_relation_violation(context, violated)\n",
    "    new_score = retriever.get_relevance_score(context, repaired)\n",
    "    \n",
    "    print(f\"Repaired (on-topic): {repaired}\")\n",
    "    print(f\"Relevance: {orig_score:.3f} ‚Üí {new_score:.3f} (Œî{new_score-orig_score:+.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PART 1 COMPLETE: Relation Repair Fixed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 2: Human Evaluation Framework\n",
    "\n",
    "Creates tools for human evaluation of response quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Part 2 - Create Human Evaluation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 2: Create Human Evaluation Samples\n",
    "Creates blinded samples for human evaluation.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Create sample evaluation data\n",
    "# In production, this would use your actual test data\n",
    "print(\"Creating human evaluation samples...\")\n",
    "\n",
    "# Sample contexts from corpus\n",
    "sample_contexts = []\n",
    "for topic, responses in corpus.items():\n",
    "    for resp in responses[:10]:  # 10 from each topic\n",
    "        sample_contexts.append({\n",
    "            \"context\": resp[\"context\"],\n",
    "            \"evidence\": \"\",\n",
    "            \"topic\": topic\n",
    "        })\n",
    "\n",
    "random.shuffle(sample_contexts)\n",
    "sample_contexts = sample_contexts[:200]  # Limit to 200\n",
    "\n",
    "# Create samples with responses from different \"systems\"\n",
    "all_samples = []\n",
    "\n",
    "for i, ctx in enumerate(sample_contexts):\n",
    "    context = ctx[\"context\"]\n",
    "    \n",
    "    # Good response (from corpus)\n",
    "    good_response = corpus[ctx[\"topic\"]][0][\"response\"] if corpus[ctx[\"topic\"]] else \"Good response.\"\n",
    "    all_samples.append({\n",
    "        \"context\": context,\n",
    "        \"evidence\": ctx[\"evidence\"],\n",
    "        \"response\": good_response,\n",
    "        \"system\": \"gricebench_repair\"\n",
    "    })\n",
    "    \n",
    "    # Off-topic response (Relation violation)\n",
    "    other_topic = random.choice([t for t in corpus.keys() if t != ctx[\"topic\"]])\n",
    "    bad_response = corpus[other_topic][0][\"response\"] if corpus[other_topic] else \"Off-topic response.\"\n",
    "    all_samples.append({\n",
    "        \"context\": context,\n",
    "        \"evidence\": ctx[\"evidence\"],\n",
    "        \"response\": bad_response,\n",
    "        \"system\": \"original_violated\"\n",
    "    })\n",
    "\n",
    "# Shuffle\n",
    "random.shuffle(all_samples)\n",
    "\n",
    "# Create blinded samples and key\n",
    "blinded_samples = []\n",
    "system_key = {}\n",
    "\n",
    "for i, sample in enumerate(all_samples):\n",
    "    system_key[str(i)] = sample[\"system\"]\n",
    "    blinded_samples.append({\n",
    "        \"id\": i,\n",
    "        \"context\": sample[\"context\"],\n",
    "        \"evidence\": sample[\"evidence\"],\n",
    "        \"response\": sample[\"response\"]\n",
    "    })\n",
    "\n",
    "# Save\n",
    "samples_path = '/kaggle/working/human_eval_samples.json'\n",
    "key_path = '/kaggle/working/human_eval_key_DO_NOT_SHARE.json'\n",
    "\n",
    "with open(samples_path, 'w') as f:\n",
    "    json.dump(blinded_samples, f, indent=2)\n",
    "\n",
    "with open(key_path, 'w') as f:\n",
    "    json.dump(system_key, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(blinded_samples)} blinded samples\")\n",
    "print(f\"   Samples: {samples_path}\")\n",
    "print(f\"   Key: {key_path} (DO NOT SHARE with annotators!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Summary & Download Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéâ PARTS 1 & 2 COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìÅ FILES CREATED:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "files = [\n",
    "    '/kaggle/working/data_processed/topical_corpus.json',\n",
    "    '/kaggle/working/data_processed/faiss_index.pkl',\n",
    "    '/kaggle/working/human_eval_samples.json',\n",
    "    '/kaggle/working/human_eval_key_DO_NOT_SHARE.json',\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    if Path(f).exists():\n",
    "        size = Path(f).stat().st_size / 1024 / 1024\n",
    "        print(f\"‚úÖ {f.split('/')[-1]:40s} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {f} NOT FOUND\")\n",
    "\n",
    "print(\"\\nüì• DOWNLOAD INSTRUCTIONS:\")\n",
    "print(\"-\"*50)\n",
    "print(\"1. Click on 'Output' tab on the right sidebar\")\n",
    "print(\"2. Download these files:\")\n",
    "print(\"   - data_processed/topical_corpus.json\")\n",
    "print(\"   - data_processed/faiss_index.pkl\")\n",
    "print(\"   - human_eval_samples.json\")\n",
    "print(\"   - human_eval_key_DO_NOT_SHARE.json\")\n",
    "print(\"\")\n",
    "print(\"3. Place them in your GriceBench folder:\")\n",
    "print(\"   GriceBench/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ data_processed/\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ topical_corpus.json\")\n",
    "print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ faiss_index.pkl\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ human_eval_samples.json\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ human_eval_key_DO_NOT_SHARE.json\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"-\"*50)\n",
    "print(\"On your laptop:\")\n",
    "print(\"1. Run: python scripts/human_eval_gradio.py\")\n",
    "print(\"   (Opens web UI for human evaluation)\")\n",
    "print(\"\")\n",
    "print(\"2. After getting ratings, run:\")\n",
    "print(\"   python scripts/analyze_human_eval.py\")\n",
    "print(\"\")\n",
    "print(\"3. Continue to Part 3: Baseline Comparisons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
