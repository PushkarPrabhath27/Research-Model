{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14639592,"sourceType":"datasetVersion","datasetId":9329674}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phase 6: Robust Detector V2 Training\n\n**Version**: 2.0 (Clean Slate Implementation)\n\n## Key Features\n- **Comprehensive Logging**: Every step is logged with clear checkpoints\n- **Data Validation**: Assertions prevent silent failures\n- **Stratified Split**: Ensures balanced validation set\n- **Dynamic pos_weight**: Calculated from training data\n- **Threshold Optimization**: Per-class threshold tuning\n- **Early Stopping**: Prevents overfitting\n\n## Execution Order\nRun ALL cells in order. Do NOT skip cells.","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 1: Environment Setup & Logging\n# ============================================================================\n\nimport os\nimport sys\nimport json\nimport time\nimport random\nimport logging\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Tuple, Optional, Any\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup comprehensive logging\nclass ColoredFormatter(logging.Formatter):\n    COLORS = {\n        'DEBUG': '\\033[36m',    # Cyan\n        'INFO': '\\033[32m',     # Green\n        'WARNING': '\\033[33m',  # Yellow\n        'ERROR': '\\033[31m',    # Red\n        'CRITICAL': '\\033[41m', # Red bg\n    }\n    RESET = '\\033[0m'\n    \n    def format(self, record):\n        color = self.COLORS.get(record.levelname, '')\n        record.levelname = f\"{color}{record.levelname}{self.RESET}\"\n        return super().format(record)\n\n# Create logger\nlogger = logging.getLogger('Phase6')\nlogger.setLevel(logging.DEBUG)\n\n# Console handler with colors\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\nconsole_format = ColoredFormatter('%(levelname)s | %(message)s')\nconsole_handler.setFormatter(console_format)\nlogger.addHandler(console_handler)\n\n# File handler for detailed logs\nos.makedirs('/kaggle/working/logs', exist_ok=True)\nfile_handler = logging.FileHandler(f'/kaggle/working/logs/training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\nfile_handler.setLevel(logging.DEBUG)\nfile_format = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\nfile_handler.setFormatter(file_format)\nlogger.addHandler(file_handler)\n\n# Checkpoint tracking\nclass CheckpointTracker:\n    def __init__(self):\n        self.checkpoints = {}\n        self.start_time = time.time()\n    \n    def mark(self, name: str, status: str = 'PASS', details: dict = None):\n        elapsed = time.time() - self.start_time\n        self.checkpoints[name] = {\n            'status': status,\n            'time': elapsed,\n            'details': details or {}\n        }\n        icon = '✅' if status == 'PASS' else '❌' if status == 'FAIL' else '⚠️'\n        logger.info(f\"{icon} CHECKPOINT [{name}]: {status}\")\n        if details:\n            for k, v in details.items():\n                logger.info(f\"   {k}: {v}\")\n    \n    def summary(self):\n        logger.info(\"=\" * 60)\n        logger.info(\"CHECKPOINT SUMMARY\")\n        logger.info(\"=\" * 60)\n        for name, data in self.checkpoints.items():\n            icon = '✅' if data['status'] == 'PASS' else '❌'\n            logger.info(f\"{icon} {name}: {data['status']} ({data['time']:.1f}s)\")\n\ntracker = CheckpointTracker()\n\n# Set seeds\ndef set_all_seeds(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_all_seeds(42)\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlogger.info(f\"Device: {device}\")\nif torch.cuda.is_available():\n    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\ntracker.mark('Environment Setup', 'PASS', {'device': str(device)})\nprint(\"\\n\" + \"=\"*60)\nprint(\"CELL 1 COMPLETE: Environment Ready\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:12:48.755827Z","iopub.execute_input":"2026-01-29T10:12:48.756030Z","iopub.status.idle":"2026-01-29T10:12:52.114317Z","shell.execute_reply.started":"2026-01-29T10:12:48.756009Z","shell.execute_reply":"2026-01-29T10:12:52.113637Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | Device: cuda\n\u001b[32mINFO\u001b[0m | GPU: Tesla T4\n\u001b[32mINFO\u001b[0m | GPU Memory: 15.8 GB\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Environment Setup]: PASS\n\u001b[32mINFO\u001b[0m |    device: cuda\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nCELL 1 COMPLETE: Environment Ready\n============================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n# CELL 2: Configuration\n# ============================================================================\n\n@dataclass\nclass Config:\n    # Paths\n    data_dir: str = '/kaggle/input/gricebench-scientific-fix'\n    output_dir: str = '/kaggle/working'\n    \n    # Model\n    model_name: str = 'microsoft/deberta-v3-small'\n    num_labels: int = 4\n    max_length: int = 256\n    \n    # Training\n    batch_size: int = 16\n    gradient_accumulation: int = 4\n    learning_rate: float = 2e-5\n    weight_decay: float = 0.01\n    num_epochs: int = 10\n    warmup_ratio: float = 0.1\n    max_grad_norm: float = 1.0\n    \n    # Early stopping\n    patience: int = 3\n    min_delta: float = 0.01\n    \n    # Data split\n    val_ratio: float = 0.15\n    test_ratio: float = 0.15\n    \n    # Mixed precision\n    fp16: bool = True\n    \n    def __post_init__(self):\n        self.effective_batch = self.batch_size * self.gradient_accumulation\n\nCONFIG = Config()\n\nlogger.info(\"Configuration:\")\nfor k, v in vars(CONFIG).items():\n    logger.info(f\"  {k}: {v}\")\n\ntracker.mark('Configuration', 'PASS')\nprint(\"\\nCELL 2 COMPLETE: Configuration set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:12:52.115622Z","iopub.execute_input":"2026-01-29T10:12:52.116052Z","iopub.status.idle":"2026-01-29T10:12:52.139337Z","shell.execute_reply.started":"2026-01-29T10:12:52.116026Z","shell.execute_reply":"2026-01-29T10:12:52.138549Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | Configuration:\n\u001b[32mINFO\u001b[0m |   data_dir: /kaggle/input/gricebench-scientific-fix\n\u001b[32mINFO\u001b[0m |   output_dir: /kaggle/working\n\u001b[32mINFO\u001b[0m |   model_name: microsoft/deberta-v3-small\n\u001b[32mINFO\u001b[0m |   num_labels: 4\n\u001b[32mINFO\u001b[0m |   max_length: 256\n\u001b[32mINFO\u001b[0m |   batch_size: 16\n\u001b[32mINFO\u001b[0m |   gradient_accumulation: 4\n\u001b[32mINFO\u001b[0m |   learning_rate: 2e-05\n\u001b[32mINFO\u001b[0m |   weight_decay: 0.01\n\u001b[32mINFO\u001b[0m |   num_epochs: 10\n\u001b[32mINFO\u001b[0m |   warmup_ratio: 0.1\n\u001b[32mINFO\u001b[0m |   max_grad_norm: 1.0\n\u001b[32mINFO\u001b[0m |   patience: 3\n\u001b[32mINFO\u001b[0m |   min_delta: 0.01\n\u001b[32mINFO\u001b[0m |   val_ratio: 0.15\n\u001b[32mINFO\u001b[0m |   test_ratio: 0.15\n\u001b[32mINFO\u001b[0m |   fp16: True\n\u001b[32mINFO\u001b[0m |   effective_batch: 64\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Configuration]: PASS\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 2 COMPLETE: Configuration set\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# CELL 3: Data Structures & Utilities\n# ============================================================================\n\n@dataclass\nclass Example:\n    \"\"\"Validated example structure\"\"\"\n    text: str\n    labels: List[int]\n    source: str\n    example_id: str = ''\n    \n    def __post_init__(self):\n        # Validation\n        if not isinstance(self.text, str):\n            raise ValueError(f\"Text must be string, got {type(self.text)}\")\n        if len(self.labels) != 4:\n            raise ValueError(f\"Labels must be length 4, got {len(self.labels)}\")\n        if not all(l in [0, 1] for l in self.labels):\n            raise ValueError(f\"Labels must be 0/1, got {self.labels}\")\n        if self.source not in ['phase4_violation', 'phase4_clean', 'synthetic']:\n            raise ValueError(f\"Invalid source: {self.source}\")\n\ndef normalize_text(raw: Any) -> str:\n    \"\"\"Convert ANY format to clean string\"\"\"\n    if raw is None:\n        return ''\n    \n    if isinstance(raw, str):\n        return raw.strip()\n    \n    if isinstance(raw, list):\n        parts = []\n        for item in raw:\n            if isinstance(item, dict):\n                speaker = item.get('speaker', 'agent')\n                text = item.get('text', '')\n                parts.append(f\"[{speaker}]: {text}\")\n            elif isinstance(item, str):\n                parts.append(item)\n        return ' '.join(parts).strip()\n    \n    if isinstance(raw, dict):\n        if 'speaker' in raw and 'text' in raw:\n            return f\"[{raw['speaker']}]: {raw['text']}\"\n        # Try common keys\n        for key in ['text', 'response', 'content']:\n            if key in raw:\n                return normalize_text(raw[key])\n        return str(raw)\n    \n    return str(raw).strip()\n\n# Test normalize_text\ntest_cases = [\n    \"Simple string\",\n    {'speaker': 'A', 'text': 'Hello'},\n    [{'speaker': 'A', 'text': 'Hi'}, {'speaker': 'B', 'text': 'Hello'}],\n    None\n]\n\nlogger.info(\"Testing normalize_text:\")\nfor tc in test_cases:\n    result = normalize_text(tc)\n    logger.debug(f\"  {type(tc).__name__} -> '{result[:50]}...'\" if len(str(result)) > 50 else f\"  {type(tc).__name__} -> '{result}'\")\n\ntracker.mark('Data Structures', 'PASS')\nprint(\"\\nCELL 3 COMPLETE: Data structures defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:12:52.140148Z","iopub.execute_input":"2026-01-29T10:12:52.140371Z","iopub.status.idle":"2026-01-29T10:12:52.155024Z","shell.execute_reply.started":"2026-01-29T10:12:52.140351Z","shell.execute_reply":"2026-01-29T10:12:52.154281Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | Testing normalize_text:\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Data Structures]: PASS\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 3 COMPLETE: Data structures defined\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n# CELL 4: Load Phase 4 Data\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"LOADING PHASE 4 DATA\")\nlogger.info(\"=\" * 60)\n\n# Check file exists\nphase4_path = f\"{CONFIG.data_dir}/natural_violations.json\"\nif not os.path.exists(phase4_path):\n    logger.error(f\"File not found: {phase4_path}\")\n    raise FileNotFoundError(phase4_path)\n\nlogger.info(f\"Loading from: {phase4_path}\")\nfile_size = os.path.getsize(phase4_path) / 1024\nlogger.info(f\"File size: {file_size:.1f} KB\")\n\nwith open(phase4_path, 'r') as f:\n    raw_data = json.load(f)\n\nlogger.info(f\"Raw records loaded: {len(raw_data)}\")\n\n# Sample inspection\nif raw_data:\n    sample = raw_data[0]\n    logger.info(f\"Sample keys: {list(sample.keys())}\")\n    logger.debug(f\"Sample record: {json.dumps(sample, indent=2)[:500]}...\")\n\n# Process violations and clean examples\nviolations = []\nclean_examples = []\nerrors = []\n\nfor idx, item in enumerate(raw_data):\n    try:\n        # Get context and combine with response\n        context = normalize_text(item.get('context', ''))\n        \n        # VIOLATION: violated_response with labels\n        violated_response = normalize_text(item.get('violated_response', ''))\n        if violated_response:\n            text = f\"{context} [SEP] {violated_response}\" if context else violated_response\n            \n            # Get labels\n            labels_dict = item.get('labels', {})\n            if isinstance(labels_dict, dict):\n                labels = [\n                    int(labels_dict.get('quantity', 0)),\n                    int(labels_dict.get('quality', 0)),\n                    int(labels_dict.get('relation', 0)),\n                    int(labels_dict.get('manner', 0))\n                ]\n            else:\n                # Infer from maxim field\n                maxim = str(item.get('maxim', '')).lower()\n                labels = [\n                    1 if 'quantity' in maxim else 0,\n                    1 if 'quality' in maxim else 0,\n                    1 if 'relation' in maxim else 0,\n                    1 if 'manner' in maxim else 0\n                ]\n            \n            if sum(labels) > 0 and len(text) > 50:\n                violations.append(Example(\n                    text=text,\n                    labels=labels,\n                    source='phase4_violation',\n                    example_id=str(item.get('id', idx))\n                ))\n        \n        # CLEAN: original_response with [0,0,0,0]\n        original_response = normalize_text(item.get('original_response', ''))\n        if original_response:\n            text = f\"{context} [SEP] {original_response}\" if context else original_response\n            if len(text) > 50:\n                clean_examples.append(Example(\n                    text=text,\n                    labels=[0, 0, 0, 0],\n                    source='phase4_clean',\n                    example_id=f\"{item.get('id', idx)}_clean\"\n                ))\n    \n    except Exception as e:\n        errors.append(f\"Item {idx}: {str(e)}\")\n\nlogger.info(f\"\\nProcessing Results:\")\nlogger.info(f\"  Violations: {len(violations)}\")\nlogger.info(f\"  Clean: {len(clean_examples)}\")\nlogger.info(f\"  Errors: {len(errors)}\")\n\nif errors[:3]:\n    logger.warning(\"Sample errors:\")\n    for e in errors[:3]:\n        logger.warning(f\"  {e}\")\n\n# Label distribution\nlogger.info(\"\\nViolation Label Distribution:\")\nmaxim_names = ['Quantity', 'Quality', 'Relation', 'Manner']\nfor i, name in enumerate(maxim_names):\n    count = sum(1 for ex in violations if ex.labels[i] == 1)\n    logger.info(f\"  {name}: {count} ({100*count/len(violations):.1f}%)\")\n\ntracker.mark('Phase 4 Data Load', 'PASS' if len(violations) > 0 else 'FAIL', {\n    'violations': len(violations),\n    'clean': len(clean_examples)\n})\n\nprint(f\"\\nCELL 4 COMPLETE: {len(violations)} violations, {len(clean_examples)} clean\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:12:52.156066Z","iopub.execute_input":"2026-01-29T10:12:52.156341Z","iopub.status.idle":"2026-01-29T10:12:52.268904Z","shell.execute_reply.started":"2026-01-29T10:12:52.156311Z","shell.execute_reply":"2026-01-29T10:12:52.268197Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | LOADING PHASE 4 DATA\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | Loading from: /kaggle/input/gricebench-scientific-fix/natural_violations.json\n\u001b[32mINFO\u001b[0m | File size: 3365.0 KB\n\u001b[32mINFO\u001b[0m | Raw records loaded: 4000\n\u001b[32mINFO\u001b[0m | Sample keys: ['id', 'original_response', 'violated_response', 'violation_type', 'maxim', 'context', 'labels', 'generation_method']\n\u001b[32mINFO\u001b[0m | \nProcessing Results:\n\u001b[32mINFO\u001b[0m |   Violations: 3970\n\u001b[32mINFO\u001b[0m |   Clean: 3880\n\u001b[32mINFO\u001b[0m |   Errors: 0\n\u001b[32mINFO\u001b[0m | \nViolation Label Distribution:\n\u001b[32mINFO\u001b[0m |   Quantity: 989 (24.9%)\n\u001b[32mINFO\u001b[0m |   Quality: 993 (25.0%)\n\u001b[32mINFO\u001b[0m |   Relation: 999 (25.2%)\n\u001b[32mINFO\u001b[0m |   Manner: 989 (24.9%)\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Phase 4 Data Load]: PASS\n\u001b[32mINFO\u001b[0m |    violations: 3970\n\u001b[32mINFO\u001b[0m |    clean: 3880\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 4 COMPLETE: 3970 violations, 3880 clean\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# CELL 5: Stratified Train/Val/Test Split\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"CREATING STRATIFIED SPLITS\")\nlogger.info(\"=\" * 60)\n\ndef stratified_split(examples: List[Example], val_ratio: float, test_ratio: float, seed: int = 42):\n    \"\"\"Split ensuring each source/label pattern appears in all splits\"\"\"\n    random.seed(seed)\n    \n    # Group by source and label pattern\n    groups = {}\n    for ex in examples:\n        key = (ex.source, tuple(ex.labels))\n        if key not in groups:\n            groups[key] = []\n        groups[key].append(ex)\n    \n    logger.info(f\"Found {len(groups)} unique source/label groups\")\n    \n    train, val, test = [], [], []\n    \n    for key, group in groups.items():\n        random.shuffle(group)\n        n = len(group)\n        \n        test_end = int(n * test_ratio)\n        val_end = test_end + int(n * val_ratio)\n        \n        test.extend(group[:test_end])\n        val.extend(group[test_end:val_end])\n        train.extend(group[val_end:])\n    \n    # Shuffle each split\n    random.shuffle(train)\n    random.shuffle(val)\n    random.shuffle(test)\n    \n    return train, val, test\n\n# Combine all examples\nall_examples = violations + clean_examples\nlogger.info(f\"Total examples before split: {len(all_examples)}\")\n\n# Split\ntrain_data, val_data, test_data = stratified_split(\n    all_examples, \n    CONFIG.val_ratio, \n    CONFIG.test_ratio\n)\n\nlogger.info(f\"\\nSplit Results:\")\nlogger.info(f\"  Train: {len(train_data)}\")\nlogger.info(f\"  Val: {len(val_data)}\")\nlogger.info(f\"  Test: {len(test_data)}\")\n\n# Verify source distribution\ndef count_sources(data):\n    from collections import Counter\n    return dict(Counter(ex.source for ex in data))\n\nlogger.info(f\"\\nSource Distribution:\")\nlogger.info(f\"  Train: {count_sources(train_data)}\")\nlogger.info(f\"  Val: {count_sources(val_data)}\")\nlogger.info(f\"  Test: {count_sources(test_data)}\")\n\n# CRITICAL: Verify val has positive examples for each maxim\nlogger.info(\"\\nValidation Set Label Check:\")\nval_labels = np.array([ex.labels for ex in val_data])\nall_positive = True\nfor i, name in enumerate(maxim_names):\n    count = val_labels[:, i].sum()\n    status = '✅' if count > 0 else '❌'\n    logger.info(f\"  {name}: {count} positives {status}\")\n    if count == 0:\n        all_positive = False\n\nif not all_positive:\n    logger.error(\"CRITICAL: Validation set missing positive examples!\")\n    raise ValueError(\"Validation set must have positive examples for all maxims\")\n\ntracker.mark('Stratified Split', 'PASS', {\n    'train': len(train_data),\n    'val': len(val_data),\n    'test': len(test_data)\n})\n\nprint(f\"\\nCELL 5 COMPLETE: Train={len(train_data)}, Val={len(val_data)}, Test={len(test_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:12:52.270992Z","iopub.execute_input":"2026-01-29T10:12:52.271213Z","iopub.status.idle":"2026-01-29T10:12:52.311849Z","shell.execute_reply.started":"2026-01-29T10:12:52.271192Z","shell.execute_reply":"2026-01-29T10:12:52.311182Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | CREATING STRATIFIED SPLITS\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | Total examples before split: 7850\n\u001b[32mINFO\u001b[0m | Found 5 unique source/label groups\n\u001b[32mINFO\u001b[0m | \nSplit Results:\n\u001b[32mINFO\u001b[0m |   Train: 5500\n\u001b[32mINFO\u001b[0m |   Val: 1175\n\u001b[32mINFO\u001b[0m |   Test: 1175\n\u001b[32mINFO\u001b[0m | \nSource Distribution:\n\u001b[32mINFO\u001b[0m |   Train: {'phase4_violation': 2784, 'phase4_clean': 2716}\n\u001b[32mINFO\u001b[0m |   Val: {'phase4_violation': 593, 'phase4_clean': 582}\n\u001b[32mINFO\u001b[0m |   Test: {'phase4_violation': 593, 'phase4_clean': 582}\n\u001b[32mINFO\u001b[0m | \nValidation Set Label Check:\n\u001b[32mINFO\u001b[0m |   Quantity: 148 positives ✅\n\u001b[32mINFO\u001b[0m |   Quality: 148 positives ✅\n\u001b[32mINFO\u001b[0m |   Relation: 149 positives ✅\n\u001b[32mINFO\u001b[0m |   Manner: 148 positives ✅\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Stratified Split]: PASS\n\u001b[32mINFO\u001b[0m |    train: 5500\n\u001b[32mINFO\u001b[0m |    val: 1175\n\u001b[32mINFO\u001b[0m |    test: 1175\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 5 COMPLETE: Train=5500, Val=1175, Test=1175\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# CELL 6: Load Tokenizer\n# ============================================================================\n\nfrom transformers import AutoTokenizer, AutoModel\n\nlogger.info(\"=\" * 60)\nlogger.info(\"LOADING TOKENIZER\")\nlogger.info(\"=\" * 60)\n\ntokenizer = AutoTokenizer.from_pretrained(CONFIG.model_name)\nlogger.info(f\"Tokenizer: {CONFIG.model_name}\")\nlogger.info(f\"Vocab size: {tokenizer.vocab_size}\")\n\n# Test tokenization\nsample_text = train_data[0].text[:200]\ntokens = tokenizer(sample_text, truncation=True, max_length=CONFIG.max_length)\nlogger.info(f\"Sample tokenization: {len(tokens['input_ids'])} tokens\")\n\ntracker.mark('Tokenizer Load', 'PASS')\nprint(\"\\nCELL 6 COMPLETE: Tokenizer ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:12:52.312775Z","iopub.execute_input":"2026-01-29T10:12:52.312988Z","iopub.status.idle":"2026-01-29T10:13:02.547760Z","shell.execute_reply.started":"2026-01-29T10:12:52.312968Z","shell.execute_reply":"2026-01-29T10:13:02.547191Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | LOADING TOKENIZER\n\u001b[32mINFO\u001b[0m | ============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778521cb6aee4ec3a8489049821a88ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a805188209794012886281b5194cec25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100723ffc80e45e69cfb20c49a5bc9c5"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m | Tokenizer: microsoft/deberta-v3-small\n\u001b[32mINFO\u001b[0m | Vocab size: 128000\n\u001b[32mINFO\u001b[0m | Sample tokenization: 66 tokens\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Tokenizer Load]: PASS\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 6 COMPLETE: Tokenizer ready\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# CELL 7: Create PyTorch Datasets\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"CREATING PYTORCH DATASETS\")\nlogger.info(\"=\" * 60)\n\nclass GriceDataset(Dataset):\n    def __init__(self, examples: List[Example], tokenizer, max_length: int):\n        self.examples = examples\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.examples)\n    \n    def __getitem__(self, idx):\n        ex = self.examples[idx]\n        \n        encoding = self.tokenizer(\n            ex.text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'labels': torch.tensor(ex.labels, dtype=torch.float32)\n        }\n\n# Create datasets\ntrain_dataset = GriceDataset(train_data, tokenizer, CONFIG.max_length)\nval_dataset = GriceDataset(val_data, tokenizer, CONFIG.max_length)\ntest_dataset = GriceDataset(test_data, tokenizer, CONFIG.max_length)\n\nlogger.info(f\"Datasets created:\")\nlogger.info(f\"  Train: {len(train_dataset)}\")\nlogger.info(f\"  Val: {len(val_dataset)}\")\nlogger.info(f\"  Test: {len(test_dataset)}\")\n\n# Verify a batch\nsample = train_dataset[0]\nlogger.info(f\"\\nSample batch shape:\")\nlogger.info(f\"  input_ids: {sample['input_ids'].shape}\")\nlogger.info(f\"  attention_mask: {sample['attention_mask'].shape}\")\nlogger.info(f\"  labels: {sample['labels'].tolist()}\")\n\ntracker.mark('Datasets Created', 'PASS')\nprint(\"\\nCELL 7 COMPLETE: Datasets ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:13:02.548626Z","iopub.execute_input":"2026-01-29T10:13:02.549115Z","iopub.status.idle":"2026-01-29T10:13:02.569744Z","shell.execute_reply.started":"2026-01-29T10:13:02.549089Z","shell.execute_reply":"2026-01-29T10:13:02.569081Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | CREATING PYTORCH DATASETS\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | Datasets created:\n\u001b[32mINFO\u001b[0m |   Train: 5500\n\u001b[32mINFO\u001b[0m |   Val: 1175\n\u001b[32mINFO\u001b[0m |   Test: 1175\n\u001b[32mINFO\u001b[0m | \nSample batch shape:\n\u001b[32mINFO\u001b[0m |   input_ids: torch.Size([256])\n\u001b[32mINFO\u001b[0m |   attention_mask: torch.Size([256])\n\u001b[32mINFO\u001b[0m |   labels: [0.0, 0.0, 1.0, 0.0]\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Datasets Created]: PASS\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 7 COMPLETE: Datasets ready\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# CELL 8: Create DataLoaders\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"CREATING DATALOADERS\")\nlogger.info(\"=\" * 60)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=CONFIG.batch_size,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=CONFIG.batch_size * 2,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CONFIG.batch_size * 2,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nlogger.info(f\"DataLoaders created:\")\nlogger.info(f\"  Train batches: {len(train_loader)}\")\nlogger.info(f\"  Val batches: {len(val_loader)}\")\nlogger.info(f\"  Test batches: {len(test_loader)}\")\nlogger.info(f\"  Effective batch size: {CONFIG.effective_batch}\")\n\ntracker.mark('DataLoaders Created', 'PASS')\nprint(\"\\nCELL 8 COMPLETE: DataLoaders ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:13:02.570639Z","iopub.execute_input":"2026-01-29T10:13:02.570906Z","iopub.status.idle":"2026-01-29T10:13:02.584779Z","shell.execute_reply.started":"2026-01-29T10:13:02.570883Z","shell.execute_reply":"2026-01-29T10:13:02.584162Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | CREATING DATALOADERS\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | DataLoaders created:\n\u001b[32mINFO\u001b[0m |   Train batches: 344\n\u001b[32mINFO\u001b[0m |   Val batches: 37\n\u001b[32mINFO\u001b[0m |   Test batches: 37\n\u001b[32mINFO\u001b[0m |   Effective batch size: 64\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [DataLoaders Created]: PASS\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 8 COMPLETE: DataLoaders ready\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================================================\n# CELL 9: Model Definition with Dynamic pos_weight\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"CREATING MODEL\")\nlogger.info(\"=\" * 60)\n\nclass MultiLabelDetector(nn.Module):\n    \"\"\"Multi-label violation detector with stored pos_weight\"\"\"\n    \n    def __init__(self, model_name: str, num_labels: int = 4, pos_weight: torch.Tensor = None):\n        super().__init__()\n        \n        self.encoder = AutoModel.from_pretrained(model_name)\n        hidden_size = self.encoder.config.hidden_size\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size // 2, num_labels)\n        )\n        \n        # CRITICAL: Store pos_weight as buffer (persists with model)\n        if pos_weight is None:\n            pos_weight = torch.ones(num_labels)\n        self.register_buffer('pos_weight', pos_weight)\n        \n        self.num_labels = num_labels\n    \n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n        logits = self.classifier(pooled)\n        \n        loss = None\n        if labels is not None:\n            loss = F.binary_cross_entropy_with_logits(\n                logits, labels, pos_weight=self.pos_weight\n            )\n        \n        return {'loss': loss, 'logits': logits}\n\n# Calculate pos_weight from training data\nlogger.info(\"\\nCalculating pos_weight from training data:\")\ntrain_labels_np = np.array([ex.labels for ex in train_data])\npos_weights = []\n\nfor i, name in enumerate(maxim_names):\n    pos = train_labels_np[:, i].sum()\n    neg = len(train_labels_np) - pos\n    weight = neg / (pos + 1e-6)  # Avoid division by zero\n    pos_weights.append(weight)\n    logger.info(f\"  {name}: pos={int(pos)}, neg={int(neg)}, weight={weight:.2f}\")\n\npos_weight_tensor = torch.tensor(pos_weights, dtype=torch.float32)\n\n# Create model\nmodel = MultiLabelDetector(\n    CONFIG.model_name,\n    num_labels=CONFIG.num_labels,\n    pos_weight=pos_weight_tensor\n).to(device)\n\n# Verify pos_weight is stored\nlogger.info(f\"\\nModel pos_weight: {model.pos_weight.tolist()}\")\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nlogger.info(f\"\\nModel parameters:\")\nlogger.info(f\"  Total: {total_params:,}\")\nlogger.info(f\"  Trainable: {trainable_params:,}\")\n\ntracker.mark('Model Created', 'PASS', {\n    'params': f\"{total_params:,}\",\n    'pos_weight': [f\"{w:.2f}\" for w in pos_weights]\n})\nprint(\"\\nCELL 9 COMPLETE: Model ready with pos_weight\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:13:02.585521Z","iopub.execute_input":"2026-01-29T10:13:02.585807Z","iopub.status.idle":"2026-01-29T10:13:22.626472Z","shell.execute_reply.started":"2026-01-29T10:13:02.585781Z","shell.execute_reply":"2026-01-29T10:13:22.625927Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | CREATING MODEL\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m | \nCalculating pos_weight from training data:\n\u001b[32mINFO\u001b[0m |   Quantity: pos=693, neg=4807, weight=6.94\n\u001b[32mINFO\u001b[0m |   Quality: pos=697, neg=4803, weight=6.89\n\u001b[32mINFO\u001b[0m |   Relation: pos=701, neg=4799, weight=6.85\n\u001b[32mINFO\u001b[0m |   Manner: pos=693, neg=4807, weight=6.94\n2026-01-29 10:13:05.066081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769681585.247271      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769681585.298076      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769681585.735251      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769681585.735270      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769681585.735273      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769681585.735275      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2c6293f81e41a89a96728cd3817479"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57423848e7b4458886189e738b5d6292"}},"metadata":{}},{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | \nModel pos_weight: [6.936507701873779, 6.890961170196533, 6.8459343910217285, 6.936507701873779]\n\u001b[32mINFO\u001b[0m:Phase6:\nModel pos_weight: [6.936507701873779, 6.890961170196533, 6.8459343910217285, 6.936507701873779]\n\u001b[32mINFO\u001b[0m | \nModel parameters:\n\u001b[32mINFO\u001b[0m:Phase6:\nModel parameters:\n\u001b[32mINFO\u001b[0m |   Total: 141,601,156\n\u001b[32mINFO\u001b[0m:Phase6:  Total: 141,601,156\n\u001b[32mINFO\u001b[0m |   Trainable: 141,601,156\n\u001b[32mINFO\u001b[0m:Phase6:  Trainable: 141,601,156\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Model Created]: PASS\n\u001b[32mINFO\u001b[0m:Phase6:✅ CHECKPOINT [Model Created]: PASS\n\u001b[32mINFO\u001b[0m |    params: 141,601,156\n\u001b[32mINFO\u001b[0m:Phase6:   params: 141,601,156\n\u001b[32mINFO\u001b[0m |    pos_weight: ['6.94', '6.89', '6.85', '6.94']\n\u001b[32mINFO\u001b[0m:Phase6:   pos_weight: ['6.94', '6.89', '6.85', '6.94']\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 9 COMPLETE: Model ready with pos_weight\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ============================================================================\n# CELL 10: Training Setup (Optimizer, Scheduler, Scaler)\n# ============================================================================\n\nfrom transformers import get_linear_schedule_with_warmup\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\nlogger.info(\"=\" * 60)\nlogger.info(\"TRAINING SETUP\")\nlogger.info(\"=\" * 60)\n\n# Optimizer\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=CONFIG.learning_rate,\n    weight_decay=CONFIG.weight_decay\n)\n\n# Scheduler\nnum_training_steps = len(train_loader) * CONFIG.num_epochs // CONFIG.gradient_accumulation\nnum_warmup_steps = int(num_training_steps * CONFIG.warmup_ratio)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps\n)\n\n# Mixed precision scaler\nscaler = torch.amp.GradScaler('cuda', enabled=CONFIG.fp16)\n\nlogger.info(f\"Optimizer: AdamW (lr={CONFIG.learning_rate})\")\nlogger.info(f\"Training steps: {num_training_steps}\")\nlogger.info(f\"Warmup steps: {num_warmup_steps}\")\nlogger.info(f\"Mixed precision: {CONFIG.fp16}\")\n\ntracker.mark('Training Setup', 'PASS')\nprint(\"\\nCELL 10 COMPLETE: Training setup ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:13:22.627335Z","iopub.execute_input":"2026-01-29T10:13:22.627878Z","iopub.status.idle":"2026-01-29T10:13:22.673388Z","shell.execute_reply.started":"2026-01-29T10:13:22.627852Z","shell.execute_reply":"2026-01-29T10:13:22.672883Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | TRAINING SETUP\n\u001b[32mINFO\u001b[0m:Phase6:TRAINING SETUP\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Optimizer: AdamW (lr=2e-05)\n\u001b[32mINFO\u001b[0m:Phase6:Optimizer: AdamW (lr=2e-05)\n\u001b[32mINFO\u001b[0m | Training steps: 860\n\u001b[32mINFO\u001b[0m:Phase6:Training steps: 860\n\u001b[32mINFO\u001b[0m | Warmup steps: 86\n\u001b[32mINFO\u001b[0m:Phase6:Warmup steps: 86\n\u001b[32mINFO\u001b[0m | Mixed precision: True\n\u001b[32mINFO\u001b[0m:Phase6:Mixed precision: True\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Training Setup]: PASS\n\u001b[32mINFO\u001b[0m:Phase6:✅ CHECKPOINT [Training Setup]: PASS\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 10 COMPLETE: Training setup ready\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================================\n# CELL 11: Evaluation Function with Detailed Metrics\n# ============================================================================\n\ndef evaluate(model, dataloader, thresholds=None, verbose=True):\n    \"\"\"\n    Evaluate model with detailed metrics per maxim.\n    Returns: macro_f1, per_class_scores, all_probs, all_labels\n    \"\"\"\n    if thresholds is None:\n        thresholds = [0.5, 0.5, 0.5, 0.5]\n    \n    model.eval()\n    all_probs = []\n    all_labels = []\n    total_loss = 0\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(input_ids, attention_mask, labels)\n            total_loss += outputs['loss'].item()\n            \n            probs = torch.sigmoid(outputs['logits']).cpu().numpy()\n            all_probs.extend(probs)\n            all_labels.extend(labels.cpu().numpy())\n    \n    all_probs = np.array(all_probs)\n    all_labels = np.array(all_labels)\n    \n    # Apply thresholds\n    all_preds = (all_probs >= np.array(thresholds)).astype(int)\n    \n    # Calculate per-class metrics\n    results = {}\n    f1_scores = []\n    \n    for i, name in enumerate(maxim_names):\n        f1 = f1_score(all_labels[:, i], all_preds[:, i], zero_division=0)\n        p = precision_score(all_labels[:, i], all_preds[:, i], zero_division=0)\n        r = recall_score(all_labels[:, i], all_preds[:, i], zero_division=0)\n        \n        f1_scores.append(f1)\n        results[name] = {'f1': f1, 'precision': p, 'recall': r}\n        \n        if verbose:\n            logger.info(f\"  {name}: F1={f1:.3f} (P={p:.3f}, R={r:.3f})\")\n    \n    macro_f1 = np.mean(f1_scores)\n    avg_loss = total_loss / len(dataloader)\n    \n    if verbose:\n        logger.info(f\"  Macro F1: {macro_f1:.4f}\")\n    \n    return {\n        'macro_f1': macro_f1,\n        'loss': avg_loss,\n        'per_class': results,\n        'all_probs': all_probs,\n        'all_labels': all_labels\n    }\n\nlogger.info(\"Evaluation function defined\")\nprint(\"\\nCELL 11 COMPLETE: Evaluation function ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:13:22.674235Z","iopub.execute_input":"2026-01-29T10:13:22.674490Z","iopub.status.idle":"2026-01-29T10:13:22.816405Z","shell.execute_reply.started":"2026-01-29T10:13:22.674467Z","shell.execute_reply":"2026-01-29T10:13:22.815708Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | Evaluation function defined\n\u001b[32mINFO\u001b[0m:Phase6:Evaluation function defined\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 11 COMPLETE: Evaluation function ready\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# CELL 12: Training Loop with Early Stopping\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"STARTING TRAINING\")\nlogger.info(\"=\" * 60)\n\n# Training state\nbest_f1 = 0.0\nbest_epoch = 0\npatience_counter = 0\ntraining_history = []\n\n# Training loop\nfor epoch in range(CONFIG.num_epochs):\n    epoch_start = time.time()\n    \n    # Training\n    model.train()\n    total_train_loss = 0\n    optimizer.zero_grad()\n    \n    for step, batch in enumerate(train_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        # Forward pass with mixed precision\n        with torch.amp.autocast('cuda', enabled=CONFIG.fp16):\n            outputs = model(input_ids, attention_mask, labels)\n            loss = outputs['loss'] / CONFIG.gradient_accumulation\n        \n        # Backward pass\n        scaler.scale(loss).backward()\n        total_train_loss += loss.item() * CONFIG.gradient_accumulation\n        \n        # Optimizer step after accumulation\n        if (step + 1) % CONFIG.gradient_accumulation == 0:\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG.max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n            optimizer.zero_grad()\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    epoch_time = time.time() - epoch_start\n    \n    # Evaluation\n    logger.info(f\"\\n{'='*60}\")\n    logger.info(f\"EPOCH {epoch + 1}/{CONFIG.num_epochs}\")\n    logger.info(f\"{'='*60}\")\n    logger.info(f\"Train Loss: {avg_train_loss:.4f} | Time: {epoch_time:.1f}s\")\n    logger.info(f\"\\nValidation Results:\")\n    \n    eval_results = evaluate(model, val_loader)\n    \n    # Track history\n    training_history.append({\n        'epoch': epoch + 1,\n        'train_loss': avg_train_loss,\n        'val_loss': eval_results['loss'],\n        'val_macro_f1': eval_results['macro_f1'],\n        'per_class': eval_results['per_class']\n    })\n    \n    # Check for improvement\n    if eval_results['macro_f1'] > best_f1 + CONFIG.min_delta:\n        best_f1 = eval_results['macro_f1']\n        best_epoch = epoch + 1\n        patience_counter = 0\n        \n        # Save best model\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_f1': best_f1,\n            'pos_weight': model.pos_weight\n        }, f'{CONFIG.output_dir}/best_model.pt')\n        \n        logger.info(f\"\\n  ✅ New best model saved! (F1={best_f1:.4f})\")\n    else:\n        patience_counter += 1\n        logger.info(f\"\\n  No improvement ({patience_counter}/{CONFIG.patience})\")\n        \n        if patience_counter >= CONFIG.patience:\n            logger.info(f\"\\n⚠️ Early stopping triggered at epoch {epoch + 1}\")\n            break\n\nlogger.info(f\"\\n{'='*60}\")\nlogger.info(f\"TRAINING COMPLETE\")\nlogger.info(f\"{'='*60}\")\nlogger.info(f\"Best Epoch: {best_epoch}\")\nlogger.info(f\"Best Val F1: {best_f1:.4f}\")\n\ntracker.mark('Training Complete', 'PASS', {\n    'best_epoch': best_epoch,\n    'best_f1': f\"{best_f1:.4f}\"\n})\n\nprint(f\"\\nCELL 12 COMPLETE: Training finished. Best F1={best_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:13:22.817416Z","iopub.execute_input":"2026-01-29T10:13:22.817706Z","iopub.status.idle":"2026-01-29T10:20:44.643353Z","shell.execute_reply.started":"2026-01-29T10:13:22.817674Z","shell.execute_reply":"2026-01-29T10:20:44.642730Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | STARTING TRAINING\n\u001b[32mINFO\u001b[0m:Phase6:STARTING TRAINING\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | EPOCH 1/10\n\u001b[32mINFO\u001b[0m:Phase6:EPOCH 1/10\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Train Loss: 1.2067 | Time: 59.7s\n\u001b[32mINFO\u001b[0m:Phase6:Train Loss: 1.2067 | Time: 59.7s\n\u001b[32mINFO\u001b[0m | \nValidation Results:\n\u001b[32mINFO\u001b[0m:Phase6:\nValidation Results:\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m |   Quantity: F1=0.655 (P=0.527, R=0.865)\n\u001b[32mINFO\u001b[0m:Phase6:  Quantity: F1=0.655 (P=0.527, R=0.865)\n\u001b[32mINFO\u001b[0m |   Quality: F1=0.244 (P=0.139, R=1.000)\n\u001b[32mINFO\u001b[0m:Phase6:  Quality: F1=0.244 (P=0.139, R=1.000)\n\u001b[32mINFO\u001b[0m |   Relation: F1=0.807 (P=0.707, R=0.940)\n\u001b[32mINFO\u001b[0m:Phase6:  Relation: F1=0.807 (P=0.707, R=0.940)\n\u001b[32mINFO\u001b[0m |   Manner: F1=0.299 (P=0.206, R=0.547)\n\u001b[32mINFO\u001b[0m:Phase6:  Manner: F1=0.299 (P=0.206, R=0.547)\n\u001b[32mINFO\u001b[0m |   Macro F1: 0.5011\n\u001b[32mINFO\u001b[0m:Phase6:  Macro F1: 0.5011\n\u001b[32mINFO\u001b[0m | \n  ✅ New best model saved! (F1=0.5011)\n\u001b[32mINFO\u001b[0m:Phase6:\n  ✅ New best model saved! (F1=0.5011)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | EPOCH 2/10\n\u001b[32mINFO\u001b[0m:Phase6:EPOCH 2/10\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Train Loss: 0.5055 | Time: 60.4s\n\u001b[32mINFO\u001b[0m:Phase6:Train Loss: 0.5055 | Time: 60.4s\n\u001b[32mINFO\u001b[0m | \nValidation Results:\n\u001b[32mINFO\u001b[0m:Phase6:\nValidation Results:\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m |   Quantity: F1=0.969 (P=0.973, R=0.966)\n\u001b[32mINFO\u001b[0m:Phase6:  Quantity: F1=0.969 (P=0.973, R=0.966)\n\u001b[32mINFO\u001b[0m |   Quality: F1=0.913 (P=0.845, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quality: F1=0.913 (P=0.845, R=0.993)\n\u001b[32mINFO\u001b[0m |   Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m:Phase6:  Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m |   Manner: F1=0.814 (P=0.786, R=0.845)\n\u001b[32mINFO\u001b[0m:Phase6:  Manner: F1=0.814 (P=0.786, R=0.845)\n\u001b[32mINFO\u001b[0m |   Macro F1: 0.9242\n\u001b[32mINFO\u001b[0m:Phase6:  Macro F1: 0.9242\n\u001b[32mINFO\u001b[0m | \n  ✅ New best model saved! (F1=0.9242)\n\u001b[32mINFO\u001b[0m:Phase6:\n  ✅ New best model saved! (F1=0.9242)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | EPOCH 3/10\n\u001b[32mINFO\u001b[0m:Phase6:EPOCH 3/10\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Train Loss: 0.1691 | Time: 60.9s\n\u001b[32mINFO\u001b[0m:Phase6:Train Loss: 0.1691 | Time: 60.9s\n\u001b[32mINFO\u001b[0m | \nValidation Results:\n\u001b[32mINFO\u001b[0m:Phase6:\nValidation Results:\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m |   Quantity: F1=0.987 (P=0.980, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quantity: F1=0.987 (P=0.980, R=0.993)\n\u001b[32mINFO\u001b[0m |   Quality: F1=0.913 (P=0.845, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quality: F1=0.913 (P=0.845, R=0.993)\n\u001b[32mINFO\u001b[0m |   Relation: F1=0.997 (P=0.993, R=1.000)\n\u001b[32mINFO\u001b[0m:Phase6:  Relation: F1=0.997 (P=0.993, R=1.000)\n\u001b[32mINFO\u001b[0m |   Manner: F1=0.843 (P=0.800, R=0.892)\n\u001b[32mINFO\u001b[0m:Phase6:  Manner: F1=0.843 (P=0.800, R=0.892)\n\u001b[32mINFO\u001b[0m |   Macro F1: 0.9349\n\u001b[32mINFO\u001b[0m:Phase6:  Macro F1: 0.9349\n\u001b[32mINFO\u001b[0m | \n  ✅ New best model saved! (F1=0.9349)\n\u001b[32mINFO\u001b[0m:Phase6:\n  ✅ New best model saved! (F1=0.9349)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | EPOCH 4/10\n\u001b[32mINFO\u001b[0m:Phase6:EPOCH 4/10\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Train Loss: 0.1159 | Time: 61.0s\n\u001b[32mINFO\u001b[0m:Phase6:Train Loss: 0.1159 | Time: 61.0s\n\u001b[32mINFO\u001b[0m | \nValidation Results:\n\u001b[32mINFO\u001b[0m:Phase6:\nValidation Results:\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m |   Quantity: F1=0.990 (P=0.987, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quantity: F1=0.990 (P=0.987, R=0.993)\n\u001b[32mINFO\u001b[0m |   Quality: F1=0.916 (P=0.850, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quality: F1=0.916 (P=0.850, R=0.993)\n\u001b[32mINFO\u001b[0m |   Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m:Phase6:  Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m |   Manner: F1=0.868 (P=0.851, R=0.885)\n\u001b[32mINFO\u001b[0m:Phase6:  Manner: F1=0.868 (P=0.851, R=0.885)\n\u001b[32mINFO\u001b[0m |   Macro F1: 0.9433\n\u001b[32mINFO\u001b[0m:Phase6:  Macro F1: 0.9433\n\u001b[32mINFO\u001b[0m | \n  No improvement (1/3)\n\u001b[32mINFO\u001b[0m:Phase6:\n  No improvement (1/3)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | EPOCH 5/10\n\u001b[32mINFO\u001b[0m:Phase6:EPOCH 5/10\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Train Loss: 0.0973 | Time: 60.8s\n\u001b[32mINFO\u001b[0m:Phase6:Train Loss: 0.0973 | Time: 60.8s\n\u001b[32mINFO\u001b[0m | \nValidation Results:\n\u001b[32mINFO\u001b[0m:Phase6:\nValidation Results:\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m |   Quantity: F1=0.997 (P=1.000, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quantity: F1=0.997 (P=1.000, R=0.993)\n\u001b[32mINFO\u001b[0m |   Quality: F1=0.916 (P=0.850, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quality: F1=0.916 (P=0.850, R=0.993)\n\u001b[32mINFO\u001b[0m |   Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m:Phase6:  Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m |   Manner: F1=0.841 (P=0.795, R=0.892)\n\u001b[32mINFO\u001b[0m:Phase6:  Manner: F1=0.841 (P=0.795, R=0.892)\n\u001b[32mINFO\u001b[0m |   Macro F1: 0.9383\n\u001b[32mINFO\u001b[0m:Phase6:  Macro F1: 0.9383\n\u001b[32mINFO\u001b[0m | \n  No improvement (2/3)\n\u001b[32mINFO\u001b[0m:Phase6:\n  No improvement (2/3)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | EPOCH 6/10\n\u001b[32mINFO\u001b[0m:Phase6:EPOCH 6/10\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Train Loss: 0.0817 | Time: 61.0s\n\u001b[32mINFO\u001b[0m:Phase6:Train Loss: 0.0817 | Time: 61.0s\n\u001b[32mINFO\u001b[0m | \nValidation Results:\n\u001b[32mINFO\u001b[0m:Phase6:\nValidation Results:\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[32mINFO\u001b[0m |   Quantity: F1=0.990 (P=0.987, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quantity: F1=0.990 (P=0.987, R=0.993)\n\u001b[32mINFO\u001b[0m |   Quality: F1=0.916 (P=0.850, R=0.993)\n\u001b[32mINFO\u001b[0m:Phase6:  Quality: F1=0.916 (P=0.850, R=0.993)\n\u001b[32mINFO\u001b[0m |   Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m:Phase6:  Relation: F1=1.000 (P=1.000, R=1.000)\n\u001b[32mINFO\u001b[0m |   Manner: F1=0.863 (P=0.835, R=0.892)\n\u001b[32mINFO\u001b[0m:Phase6:  Manner: F1=0.863 (P=0.835, R=0.892)\n\u001b[32mINFO\u001b[0m |   Macro F1: 0.9421\n\u001b[32mINFO\u001b[0m:Phase6:  Macro F1: 0.9421\n\u001b[32mINFO\u001b[0m | \n  No improvement (3/3)\n\u001b[32mINFO\u001b[0m:Phase6:\n  No improvement (3/3)\n\u001b[32mINFO\u001b[0m | \n⚠️ Early stopping triggered at epoch 6\n\u001b[32mINFO\u001b[0m:Phase6:\n⚠️ Early stopping triggered at epoch 6\n\u001b[32mINFO\u001b[0m | \n============================================================\n\u001b[32mINFO\u001b[0m:Phase6:\n============================================================\n\u001b[32mINFO\u001b[0m | TRAINING COMPLETE\n\u001b[32mINFO\u001b[0m:Phase6:TRAINING COMPLETE\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | Best Epoch: 3\n\u001b[32mINFO\u001b[0m:Phase6:Best Epoch: 3\n\u001b[32mINFO\u001b[0m | Best Val F1: 0.9349\n\u001b[32mINFO\u001b[0m:Phase6:Best Val F1: 0.9349\n\u001b[32mINFO\u001b[0m | ✅ CHECKPOINT [Training Complete]: PASS\n\u001b[32mINFO\u001b[0m:Phase6:✅ CHECKPOINT [Training Complete]: PASS\n\u001b[32mINFO\u001b[0m |    best_epoch: 3\n\u001b[32mINFO\u001b[0m:Phase6:   best_epoch: 3\n\u001b[32mINFO\u001b[0m |    best_f1: 0.9349\n\u001b[32mINFO\u001b[0m:Phase6:   best_f1: 0.9349\n","output_type":"stream"},{"name":"stdout","text":"\nCELL 12 COMPLETE: Training finished. Best F1=0.9349\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ============================================================================\n# CELL 13: Threshold Optimization\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"THRESHOLD OPTIMIZATION\")\nlogger.info(\"=\" * 60)\n\n# Load best model\ncheckpoint = torch.load(f'{CONFIG.output_dir}/best_model.pt')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nlogger.info(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n\n# Get predictions on validation set\neval_results = evaluate(model, val_loader, verbose=False)\nall_probs = eval_results['all_probs']\nall_labels = eval_results['all_labels']\n\n# Find optimal thresholds\noptimal_thresholds = []\n\nlogger.info(\"\\nFinding optimal thresholds per maxim:\")\nfor i, name in enumerate(maxim_names):\n    best_f1 = 0\n    best_thresh = 0.5\n    \n    for thresh in np.arange(0.1, 0.9, 0.05):\n        preds = (all_probs[:, i] >= thresh).astype(int)\n        f1 = f1_score(all_labels[:, i], preds, zero_division=0)\n        \n        if f1 > best_f1:\n            best_f1 = f1\n            best_thresh = thresh\n    \n    optimal_thresholds.append(best_thresh)\n    \n    # Compare with default\n    default_preds = (all_probs[:, i] >= 0.5).astype(int)\n    default_f1 = f1_score(all_labels[:, i], default_preds, zero_division=0)\n    \n    improvement = best_f1 - default_f1\n    logger.info(f\"  {name}: thresh={best_thresh:.2f} (F1: {default_f1:.3f} -> {best_f1:.3f}, +{improvement:.3f})\")\n\n# Final evaluation with optimal thresholds\nlogger.info(\"\\n\" + \"=\"*60)\nlogger.info(\"FINAL EVALUATION (Optimal Thresholds)\")\nlogger.info(\"=\"*60)\n\nfinal_results = evaluate(model, val_loader, thresholds=optimal_thresholds)\n\nlogger.info(f\"\\nMacro F1 with optimal thresholds: {final_results['macro_f1']:.4f}\")\n\n# Save thresholds\nthreshold_config = {\n    'thresholds': {name: thresh for name, thresh in zip(maxim_names, optimal_thresholds)},\n    'macro_f1': final_results['macro_f1']\n}\n\nwith open(f'{CONFIG.output_dir}/optimal_thresholds.json', 'w') as f:\n    json.dump(threshold_config, f, indent=2)\n\ntracker.mark('Threshold Optimization', 'PASS', {\n    'final_f1': f\"{final_results['macro_f1']:.4f}\"\n})\n\nprint(f\"\\nCELL 13 COMPLETE: Optimal F1={final_results['macro_f1']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:20:44.644770Z","iopub.execute_input":"2026-01-29T10:20:44.645029Z","iopub.status.idle":"2026-01-29T10:20:45.999885Z","shell.execute_reply.started":"2026-01-29T10:20:44.644996Z","shell.execute_reply":"2026-01-29T10:20:45.998686Z"}},"outputs":[{"name":"stderr","text":"\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n\u001b[32mINFO\u001b[0m | THRESHOLD OPTIMIZATION\n\u001b[32mINFO\u001b[0m:Phase6:THRESHOLD OPTIMIZATION\n\u001b[32mINFO\u001b[0m | ============================================================\n\u001b[32mINFO\u001b[0m:Phase6:============================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1179804695.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{CONFIG.output_dir}/best_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded best model from epoch {checkpoint['epoch']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1527\u001b[0m                         )\n\u001b[1;32m   1528\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 return _load(\n\u001b[1;32m   1531\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."],"ename":"UnpicklingError","evalue":"Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# ============================================================================\n# CELL 14: Final Test Set Evaluation\n# ============================================================================\n\nlogger.info(\"=\" * 60)\nlogger.info(\"TEST SET EVALUATION\")\nlogger.info(\"=\" * 60)\n\ntest_results = evaluate(model, test_loader, thresholds=optimal_thresholds)\n\nlogger.info(f\"\\nTest Set Macro F1: {test_results['macro_f1']:.4f}\")\n\n# Save final results\nfinal_report = {\n    'model': CONFIG.model_name,\n    'best_epoch': best_epoch,\n    'thresholds': {name: thresh for name, thresh in zip(maxim_names, optimal_thresholds)},\n    'validation': {\n        'macro_f1': final_results['macro_f1'],\n        'per_class': final_results['per_class']\n    },\n    'test': {\n        'macro_f1': test_results['macro_f1'],\n        'per_class': test_results['per_class']\n    },\n    'training_history': training_history\n}\n\nwith open(f'{CONFIG.output_dir}/detector_v2_results.json', 'w') as f:\n    json.dump(final_report, f, indent=2, default=str)\n\ntracker.mark('Test Evaluation', 'PASS', {\n    'test_f1': f\"{test_results['macro_f1']:.4f}\"\n})\n\nprint(f\"\\nCELL 14 COMPLETE: Test F1={test_results['macro_f1']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:20:46.000612Z","iopub.status.idle":"2026-01-29T10:20:46.001201Z","shell.execute_reply.started":"2026-01-29T10:20:46.000826Z","shell.execute_reply":"2026-01-29T10:20:46.000848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 15: Final Summary\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 6 DETECTOR V2 TRAINING COMPLETE\")\nprint(\"=\"*70)\n\n# Checkpoint summary\ntracker.summary()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS\")\nprint(\"=\"*70)\n\nprint(f\"\\nValidation Macro F1: {final_results['macro_f1']:.4f}\")\nprint(f\"Test Macro F1:       {test_results['macro_f1']:.4f}\")\n\nprint(f\"\\nPer-Class Test Results:\")\nfor name, metrics in test_results['per_class'].items():\n    print(f\"  {name}: F1={metrics['f1']:.3f} (P={metrics['precision']:.3f}, R={metrics['recall']:.3f})\")\n\nprint(f\"\\nOptimal Thresholds:\")\nfor name, thresh in zip(maxim_names, optimal_thresholds):\n    print(f\"  {name}: {thresh:.2f}\")\n\nprint(f\"\\nOutput Files:\")\nprint(f\"  {CONFIG.output_dir}/best_model.pt\")\nprint(f\"  {CONFIG.output_dir}/detector_v2_results.json\")\nprint(f\"  {CONFIG.output_dir}/optimal_thresholds.json\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"✅ ALL COMPLETE - Download results from /kaggle/working/\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T10:20:46.002367Z","iopub.status.idle":"2026-01-29T10:20:46.002704Z","shell.execute_reply.started":"2026-01-29T10:20:46.002538Z","shell.execute_reply":"2026-01-29T10:20:46.002562Z"}},"outputs":[],"execution_count":null}]}