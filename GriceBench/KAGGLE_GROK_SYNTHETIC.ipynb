{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Synthetic Data Generation with Grok API\n",
                "\n",
                "**Instructions:**\n",
                "1. Upload `scored_data.json` as a dataset\n",
                "2. Get your Grok API key from console.x.ai\n",
                "3. Run the cells below\n",
                "4. Download `synthetic_candidates.json` when done"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install OpenAI SDK (Grok is compatible)\n",
                "!pip install -q openai tqdm\n",
                "\n",
                "import os\n",
                "import json\n",
                "import time\n",
                "from tqdm import tqdm\n",
                "from openai import OpenAI\n",
                "\n",
                "print(\"✅ Libraries installed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================\n",
                "# CONFIGURATION\n",
                "# ============================\n",
                "\n",
                "# API Key Input\n",
                "print(\"Enter your Grok API Key from console.x.ai:\")\n",
                "API_KEY = input(\"API Key: \").strip()\n",
                "\n",
                "if len(API_KEY) < 10:\n",
                "    raise ValueError(\"Invalid API key!\")\n",
                "\n",
                "# Initialize Grok client (OpenAI-compatible)\n",
                "client = OpenAI(\n",
                "    api_key=API_KEY,\n",
                "    base_url=\"https://api.x.ai/v1\"\n",
                ")\n",
                "\n",
                "print(\"✅ Grok client configured\")\n",
                "\n",
                "# Find input data\n",
                "POSSIBLE_PATHS = [\n",
                "    \"/kaggle/input/gricebench-scored/scored_data.json\",\n",
                "    \"/kaggle/input/scored-data/scored_data.json\",\n",
                "    \"scored_data.json\"\n",
                "]\n",
                "INPUT_FILE = next((p for p in POSSIBLE_PATHS if os.path.exists(p)), None)\n",
                "\n",
                "if not INPUT_FILE:\n",
                "    raise FileNotFoundError(\"scored_data.json not found! Upload it as a dataset.\")\n",
                "\n",
                "print(f\"✅ Found: {INPUT_FILE}\")\n",
                "OUTPUT_FILE = \"/kaggle/working/synthetic_candidates.json\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================\n",
                "# GENERATION LOGIC\n",
                "# ============================\n",
                "\n",
                "# Strict Gricean System Prompt\n",
                "SYSTEM_INSTRUCTION = \"\"\"You are a Gricean Cooperative Assistant.\n",
                "Your task is to generate responses that strictly adhere to all four Gricean Maxims:\n",
                "1. Quantity: Be as informative as required, but no more.\n",
                "2. Quality: Do not say what you believe to be false or lack evidence for.\n",
                "3. Relation: Be strictly relevant to the user's prompt.\n",
                "4. Manner: Be perspicuous—avoid obscurity, ambiguity, and unnecessary verbosity. Be orderly and polite.\n",
                "\n",
                "Context: You are providing a 'chosen' response for a DPO dataset.\n",
                "Your output must be significantly better than a typical chatbot response in terms of cooperation and clarity.\n",
                "Do not be chatty. Do not offer unsolicited advice. Answer the prompt directly and cooperatively.\"\"\"\n",
                "\n",
                "def get_failed_prompts(data_path):\n",
                "    with open(data_path, 'r') as f: data = json.load(f)\n",
                "    candidates = []\n",
                "    for entry in data:\n",
                "        m = entry.get('margins', {})\n",
                "        if not (m.get('quantity',0)>0 and m.get('quality',0)>0 and m.get('relation',0)>0 and m.get('manner',0)>0):\n",
                "            candidates.append(entry)\n",
                "    return candidates\n",
                "\n",
                "def run_generation():\n",
                "    all_candidates = get_failed_prompts(INPUT_FILE)\n",
                "    print(f\"Target prompts: {len(all_candidates)}\")\n",
                "    \n",
                "    # Resume capability\n",
                "    completed = []\n",
                "    if os.path.exists(OUTPUT_FILE):\n",
                "        try:\n",
                "            with open(OUTPUT_FILE, 'r') as f: completed = json.load(f)\n",
                "            print(f\"Resuming: {len(completed)} done\")\n",
                "        except: pass\n",
                "    \n",
                "    completed_prompts = {c['prompt'] for c in completed}\n",
                "    todos = [c for c in all_candidates if c['prompt'] not in completed_prompts]\n",
                "    print(f\"Remaining: {len(todos)}\")\n",
                "    print(\"Starting generation...\")\n",
                "\n",
                "    try:\n",
                "        count = 0\n",
                "        for i, item in enumerate(tqdm(todos)):\n",
                "            try:\n",
                "                # Call Grok API\n",
                "                response = client.chat.completions.create(\n",
                "                    model=\"grok-2-1212\",  # Latest Grok model\n",
                "                    messages=[\n",
                "                        {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION},\n",
                "                        {\"role\": \"user\", \"content\": item['prompt']}\n",
                "                    ],\n",
                "                    temperature=0.7,\n",
                "                    max_tokens=1024\n",
                "                )\n",
                "                \n",
                "                text = response.choices[0].message.content.strip()\n",
                "                \n",
                "                # Save result\n",
                "                res_entry = item.copy()\n",
                "                res_entry['synthetic_chosen'] = text\n",
                "                res_entry['original_chosen_failed'] = item['chosen']\n",
                "                res_entry['chosen'] = text\n",
                "                \n",
                "                completed.append(res_entry)\n",
                "                count += 1\n",
                "                \n",
                "                # Autosave every 10\n",
                "                if count % 10 == 0:\n",
                "                    with open(OUTPUT_FILE, 'w') as f: json.dump(completed, f, indent=2)\n",
                "                \n",
                "                # Rate limit: Grok free tier ~15 RPM\n",
                "                time.sleep(4.5)\n",
                "                \n",
                "            except Exception as e:\n",
                "                print(f\"\\nError {i}: {e}\")\n",
                "                time.sleep(30)  # Longer backoff for quota errors\n",
                "                \n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\nStopped.\")\n",
                "    finally:\n",
                "        with open(OUTPUT_FILE, 'w') as f: json.dump(completed, f, indent=2)\n",
                "        print(f\"\\n✅ {len(completed)} items saved to {OUTPUT_FILE}\")\n",
                "\n",
                "run_generation()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}